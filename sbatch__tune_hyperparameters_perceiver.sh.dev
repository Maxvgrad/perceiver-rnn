#!/bin/bash -l
#SBATCH --job-name="NN-project-rally-challenge-24-tune-perceiver"
#SBATCH --time=24:00:00 # set an appropriate amount of time for the job to run here in HH:MM:SS format
#SBATCH --partition=gpu # set the partition to gpu
#SBATCH --gres=gpu:tesla:1 # assign a single tesla gpu
#SBATCH --output=slurm/%j_slurm_%x.out # STDOUT
#SBATCH --mem=32G
#SBATCH --cpus-per-task=4

# Here you need to run train.py with python from the virtual environment where you have all the dependencies install
# You also have to pass the command line args (such as dataset name) to the script here, as well
# You may use whichever virtual environment manager you prefer (conda, venv, etc.)

module load miniconda3
module load py-protobuf/3.20.0

source activate rally_challenge_env

python experiment.py \
  --mode tune_hyperparameters \
  --model-name perceiver \
  --model-type perceiver \
  --loss mse \
  --wandb-project wandb-tune-perceiver-v1 \
  --wandb-sweep-name wandb-sweep-tune-perceiver-v1 \
  --dataset-folder="/gpfs/space/projects/rally2023/rally-estonia-cropped-antialias" \
  --batch-size 512 \
  --learning-rate 0.000712 \
  --weight-decay 0.026266 \
  --patience 2 \
  --max-epochs 6 \
  --dataset-proportion 0.1 \
  --perceiver-seq-length 128 \
  --perceiver-stride 128 \
  --perceiver-img-pre-type cnn \
  --perceiver-in-channels 3 \
  --perceiver-latent-dim 256 \
  --num-workers 2